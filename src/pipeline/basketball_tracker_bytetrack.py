"""Basketball Tracker with ByteTrack

A simpler, faster alternative to DeepSORT-based tracking.
Uses ByteTrack for motion-based tracking without appearance features.
"""

import cv2
import numpy as np
import time
import yaml
from typing import List, Dict, Tuple, Optional
from pathlib import Path
import json

from src.detection.yolo_detector import YOLODetector
from src.segmentation.sam2_segmenter import SAM2Segmenter
from src.tracking.bytetrack_tracker import ByteTrackTracker
from collections import deque


class DetectionSmoother:
    """
    Smooths detections to reduce noise and improve tracking stability
    """
    
    def __init__(self, history_size: int = 5, confidence_threshold: float = 0.3):
        """
        Initialize detection smoother
        
        Args:
            history_size: Number of frames to keep in history for smoothing
            confidence_threshold: Minimum confidence for detection persistence
        """
        self.history_size = history_size
        self.confidence_threshold = confidence_threshold
        self.detection_history = deque(maxlen=history_size)
        self.frame_count = 0
    
    def smooth_detections(self, detections: List[Dict]) -> List[Dict]:
        """
        Apply smoothing to detections
        
        Args:
            detections: List of raw detections from YOLO
            
        Returns:
            List of smoothed detections
        """
        self.frame_count += 1
        
        # Store current detections in history
        self.detection_history.append(detections)
        
        # If we don't have enough history, just apply basic filtering
        if len(self.detection_history) < 3:
            return self._apply_confidence_smoothing(detections)
        
        # Apply full smoothing pipeline
        smoothed_detections = []
        
        for detection in detections:
            # Step 1: Smooth confidence scores
            smoothed_confidence = self._smooth_confidence(detection)
            
            # Step 2: Check detection persistence
            if not self._check_detection_persistence(detection):
                continue  # Skip non-persistent detections
            
            # Step 3: Smooth centroid position
            smoothed_bbox = self._smooth_bbox_position(detection)
            
            # Create smoothed detection
            smoothed_detection = detection.copy()
            smoothed_detection['confidence'] = smoothed_confidence
            smoothed_detection['bbox'] = smoothed_bbox
            smoothed_detection['smoothed'] = True
            
            smoothed_detections.append(smoothed_detection)
        
        return smoothed_detections
    
    def _apply_confidence_smoothing(self, detections: List[Dict]) -> List[Dict]:
        """Apply basic confidence filtering when history is insufficient"""
        filtered_detections = []
        for detection in detections:
            if detection['confidence'] >= self.confidence_threshold:
                filtered_detections.append(detection)
        return filtered_detections
    
    def _smooth_confidence(self, detection: Dict) -> float:
        """Smooth confidence scores over recent frames"""
        bbox = detection['bbox']
        confidence_values = []
        
        # Look for similar detections in recent frames
        for frame_detections in list(self.detection_history)[-3:]:  # Last 3 frames
            for hist_detection in frame_detections:
                if self._detections_overlap(bbox, hist_detection['bbox']):
                    confidence_values.append(hist_detection['confidence'])
        
        if confidence_values:
            # Use median of recent confidence values
            return float(np.median(confidence_values))
        else:
            return detection['confidence']
    
    def _check_detection_persistence(self, detection: Dict) -> bool:
        """Check if detection has appeared in multiple recent frames"""
        if len(self.detection_history) < 2:
            return detection['confidence'] >= self.confidence_threshold
        
        bbox = detection['bbox']
        matches_in_history = 0
        
        # Check last 3 frames for similar detections
        for frame_detections in list(self.detection_history)[-3:]:
            for hist_detection in frame_detections:
                if self._detections_overlap(bbox, hist_detection['bbox']):
                    matches_in_history += 1
                    break
        
        # Require detection to appear in at least 2 of last 3 frames for new tracks
        # Or have high confidence for immediate acceptance
        return matches_in_history >= 2 or detection['confidence'] >= 0.7
    
    def _smooth_bbox_position(self, detection: Dict) -> List[float]:
        """Smooth bounding box position using median filtering"""
        bbox = detection['bbox']
        recent_bboxes = []
        
        # Collect similar bboxes from recent frames
        for frame_detections in list(self.detection_history)[-5:]:  # Last 5 frames
            for hist_detection in frame_detections:
                if self._detections_overlap(bbox, hist_detection['bbox']):
                    recent_bboxes.append(hist_detection['bbox'])
        
        if len(recent_bboxes) >= 3:
            # Apply median filtering to bbox coordinates
            recent_bboxes = np.array(recent_bboxes)
            smoothed_bbox = np.median(recent_bboxes, axis=0).tolist()
            return smoothed_bbox
        else:
            return bbox
    
    def _detections_overlap(self, bbox1: List[float], bbox2: List[float], threshold: float = 0.3) -> bool:
        """Check if two bounding boxes overlap significantly"""
        x1_1, y1_1, x2_1, y2_1 = bbox1
        x1_2, y1_2, x2_2, y2_2 = bbox2
        
        # Calculate intersection
        x1_i = max(x1_1, x1_2)
        y1_i = max(y1_1, y1_2)
        x2_i = min(x2_1, x2_2)
        y2_i = min(y2_1, y2_2)
        
        if x2_i <= x1_i or y2_i <= y1_i:
            return False  # No intersection
        
        # Calculate areas
        intersection_area = (x2_i - x1_i) * (y2_i - y1_i)
        area1 = (x2_1 - x1_1) * (y2_1 - y1_1)
        area2 = (x2_2 - x1_2) * (y2_2 - y1_2)
        union_area = area1 + area2 - intersection_area
        
        # Calculate IoU (Intersection over Union)
        iou = intersection_area / union_area if union_area > 0 else 0
        return iou >= threshold


class BasketballTrackerByteTrack:
    """
    Basketball player tracking pipeline using ByteTrack
    
    Simpler and faster than DeepSORT-based approach.
    """
    
    def __init__(
        self,
        yolo_config_path: Optional[str] = None,
        sam2_config_path: Optional[str] = None,
        optimization_level: str = "balanced",
        mask_only_visualization: bool = False
    ):
        """
        Initialize ByteTrack-based basketball tracking pipeline
        
        Args:
            yolo_config_path: Path to YOLO configuration
            sam2_config_path: Path to SAM2 configuration  
            optimization_level: 'fast', 'balanced', or 'quality'
            mask_only_visualization: If True, show only segmentation masks without bounding boxes
        """
        self.optimization_level = optimization_level
        self.mask_only_visualization = mask_only_visualization
        
        print("ðŸ€ Initializing ByteTrack Basketball Tracking Pipeline")
        print("=" * 60)
        print(f"Optimization level: {optimization_level}")
        print(f"Mask-only visualization: {mask_only_visualization}")
        
        # Configure optimization settings
        self._configure_optimization(optimization_level)
        
        # Initialize components
        self._initialize_components(yolo_config_path, sam2_config_path)
        
        # Initialize detection smoother
        self.detection_smoother = DetectionSmoother(
            history_size=5,
            confidence_threshold=0.25 if optimization_level == "fast" else 0.3
        )
        
        # Performance tracking
        self.frame_count = 0
        self.processing_times = {
            'detection': [],
            'segmentation': [],
            'tracking': [],
            'visualization': [],
            'total': []
        }
        
        # Team classification (simple color-based)
        self.team_colors = {
            'red': (0, 0, 255),
            'green': (0, 255, 0),
            'blue': (255, 0, 0),
            'cyan': (255, 255, 0),
            'magenta': (255, 0, 255),
            'yellow': (0, 255, 255),
            'purple': (128, 0, 128),
            'orange': (0, 165, 255),
            'unknown': (128, 128, 128)
        }
        
        # Statistics tracking
        self.session_stats = {
            'total_frames': 0,
            'total_detections': 0,
            'unique_tracks': set(),
            'max_simultaneous_players': 0
        }
        
        print("âœ… ByteTrack basketball tracking pipeline initialized successfully!")
        print(f"Components: YOLO âœ… | SAM2 {'âœ…' if self.sam2_available else 'âš ï¸ '} | ByteTrack âœ…")
    
    def _configure_optimization(self, level: str):
        """Configure pipeline based on optimization level"""
        if level == "fast":
            self.yolo_model = "yolo11s.pt"  # Small model for better detection
            self.sam2_model = "sam2_hiera_t.yaml"  # Tiny for speed
            self.sam2_checkpoint = "sam2_hiera_tiny.pt"
            self.process_every_n_frames = 1
            self.enable_segmentation = True  # Enable segmentation with tiny model
            self.enable_advanced_tracking = True
            # ByteTrack settings for speed
            self.track_activation_threshold = 0.2
            self.lost_track_buffer = 30
            self.minimum_matching_threshold = 0.7
        
        elif level == "balanced":
            self.yolo_model = "yolo11m.pt"
            self.sam2_model = "sam2_hiera_b+.yaml"  # Base Plus for balanced
            self.sam2_checkpoint = "sam2_hiera_base_plus.pt"
            self.process_every_n_frames = 1
            self.enable_segmentation = True
            self.enable_advanced_tracking = True
            # ByteTrack settings for balance
            self.track_activation_threshold = 0.25
            self.lost_track_buffer = 50
            self.minimum_matching_threshold = 0.8
        
        elif level == "quality":  # quality
            self.yolo_model = "yolo11l.pt"
            self.sam2_model = "sam2_hiera_l.yaml"  # Large for quality
            self.sam2_checkpoint = "sam2_hiera_large.pt"
            self.process_every_n_frames = 1
            self.enable_segmentation = True
            self.enable_advanced_tracking = True
            # ByteTrack settings for quality
            self.track_activation_threshold = 0.3
            self.lost_track_buffer = 60
            self.minimum_matching_threshold = 0.85
    
    def _initialize_components(self, yolo_config, sam2_config):
        """Initialize all pipeline components"""
        
        # Initialize YOLO detector
        print("ðŸŽ¯ Initializing YOLO detector...")
        try:
            # Construct full path to model
            model_path = f"models/yolo/{self.yolo_model}"
            self.detector = YOLODetector(
                model_path=model_path,
                config_path=yolo_config or "config/yolo_config.yaml"
            )
            self.yolo_available = True
            print("âœ… YOLO detector ready")
        except Exception as e:
            print(f"âŒ YOLO initialization failed: {e}")
            raise
        
        # Initialize SAM2 segmenter (optional)
        if self.enable_segmentation:
            print("ðŸ–¼ï¸  Initializing SAM2 segmenter...")
            try:
                self.segmenter = SAM2Segmenter(
                    model_cfg=self.sam2_model,
                    checkpoint=self.sam2_checkpoint,
                    config_path=sam2_config or "config/sam2_config.yaml"
                )
                self.sam2_available = True
                print("âœ… SAM2 segmenter ready")
            except Exception as e:
                print(f"âš ï¸  SAM2 initialization failed: {e}")
                print("Continuing with bounding box mode...")
                self.segmenter = None
                self.sam2_available = False
        else:
            self.segmenter = None
            self.sam2_available = False
            print("âš ï¸  SAM2 segmentation disabled for speed")
        
        # Initialize ByteTrack tracker
        print("ðŸ‘¥ Initializing ByteTrack tracker...")
        try:
            self.tracker = ByteTrackTracker(
                track_activation_threshold=self.track_activation_threshold,
                lost_track_buffer=self.lost_track_buffer,
                minimum_matching_threshold=self.minimum_matching_threshold,
                frame_rate=30
            )
            self.tracker_available = True
            print("âœ… ByteTrack tracker ready")
        except Exception as e:
            print(f"âŒ ByteTrack initialization failed: {e}")
            raise
    
    def process_frame(self, frame: np.ndarray) -> Tuple[np.ndarray, List[Dict]]:
        """
        Process single frame through ByteTrack pipeline
        
        Args:
            frame: Input frame (BGR format)
            
        Returns:
            Tuple of (visualized_frame, tracked_players)
        """
        start_time = time.time()
        
        try:
            # Step 1: YOLO Detection
            detection_start = time.time()
            raw_detections = self.detector.detect_players(frame)
            
            # Step 1.5: Apply detection smoothing
            detections = self.detection_smoother.smooth_detections(raw_detections)
            
            # Store for debug display
            self._last_raw_detections = raw_detections
            self._last_smoothed_detections = detections
            
            detection_time = time.time() - detection_start
            self.processing_times['detection'].append(detection_time)
            
            # Step 2: SAM2 Segmentation (optional)
            segmentation_start = time.time()
            if self.sam2_available and self.segmenter and detections:
                segmented_detections = self.segmenter.segment_players(frame, detections)
            else:
                # Create fallback masks for visualization
                segmented_detections = self._create_fallback_masks(frame, detections)
            
            segmentation_time = time.time() - segmentation_start
            self.processing_times['segmentation'].append(segmentation_time)
            
            # Step 3: ByteTrack Tracking
            tracking_start = time.time()
            if segmented_detections:
                tracked_players = self.tracker.update(segmented_detections, frame)
            else:
                tracked_players = []
            
            tracking_time = time.time() - tracking_start
            self.processing_times['tracking'].append(tracking_time)
            
            # Step 4: Enhance tracks with segmentation data
            enhanced_tracks = self._enhance_tracks_with_segmentation(
                tracked_players, segmented_detections
            )
            
            # Step 5: Visualization
            visualization_start = time.time()
            if self.mask_only_visualization:
                vis_frame = self.visualize_masks_only(frame, enhanced_tracks)
            else:
                vis_frame = self.visualize_tracking(frame, enhanced_tracks)
            visualization_time = time.time() - visualization_start
            self.processing_times['visualization'].append(visualization_time)
            
            # Update statistics
            self._update_statistics(enhanced_tracks)
            
            # Record total processing time
            total_time = time.time() - start_time
            self.processing_times['total'].append(total_time)
            self.frame_count += 1
            
            return vis_frame, enhanced_tracks
            
        except Exception as e:
            print(f"Warning: Frame processing failed: {e}")
            self.frame_count += 1
            return frame, []
    
    def _create_fallback_masks(self, frame: np.ndarray, detections: List[Dict]) -> List[Dict]:
        """Create rectangular masks when SAM2 is not available"""
        segmented_detections = []
        
        for detection in detections:
            bbox = detection['bbox']
            x1, y1, x2, y2 = [int(coord) for coord in bbox]
            
            # Create rectangular mask
            mask = np.zeros(frame.shape[:2], dtype=bool)
            mask[y1:y2, x1:x2] = True
            
            # Add mask information
            detection_with_mask = detection.copy()
            detection_with_mask.update({
                'mask': mask,
                'mask_score': 0.8,
                'has_mask': True,
                'mask_type': 'fallback'
            })
            
            segmented_detections.append(detection_with_mask)
        
        return segmented_detections
    
    def _enhance_tracks_with_segmentation(
        self, 
        tracked_players: List[Dict], 
        segmented_detections: List[Dict]
    ) -> List[Dict]:
        """Enhance tracking results with segmentation information"""
        
        enhanced_tracks = []
        for track in tracked_players:
            enhanced_track = track.copy()
            
            # Find matching segmentation by bbox proximity
            track_bbox = track['bbox']
            track_center = [(track_bbox[0] + track_bbox[2]) / 2, (track_bbox[1] + track_bbox[3]) / 2]
            
            matching_seg = None
            min_distance = float('inf')
            
            for seg_det in segmented_detections:
                seg_bbox = seg_det['bbox']
                seg_center = [(seg_bbox[0] + seg_bbox[2]) / 2, (seg_bbox[1] + seg_bbox[3]) / 2]
                
                distance = np.sqrt((track_center[0] - seg_center[0])**2 + 
                                 (track_center[1] - seg_center[1])**2)
                
                if distance < min_distance and distance < 50:  # 50 pixel threshold
                    min_distance = distance
                    matching_seg = seg_det
            
            # Add segmentation information if found
            if matching_seg:
                enhanced_track['mask'] = matching_seg.get('mask')
                enhanced_track['mask_score'] = matching_seg.get('mask_score', 0.0)
                enhanced_track['has_mask'] = matching_seg.get('has_mask', False)
                enhanced_track['mask_type'] = matching_seg.get('mask_type', 'sam2')
                enhanced_track['detection_confidence'] = matching_seg.get('confidence', 0.0)
            else:
                enhanced_track['has_mask'] = False
            
            enhanced_tracks.append(enhanced_track)
        
        return enhanced_tracks
    
    def visualize_masks_only(self, frame: np.ndarray, tracked_players: List[Dict]) -> np.ndarray:
        """Visualize only segmentation masks without bounding boxes"""
        vis_frame = frame.copy()
        
        if not tracked_players:
            self._draw_performance_info(vis_frame)
            return vis_frame
        
        # Color palette for different track IDs
        color_palette = list(self.team_colors.values())[:-1]  # Exclude 'unknown'
        
        # Draw each tracked player - MASKS ONLY
        for player in tracked_players:
            track_id = player['track_id']
            
            # Get consistent color for track ID
            color = color_palette[track_id % len(color_palette)]
            
            # Draw segmentation mask if available
            if player.get('has_mask', False) and 'mask' in player:
                mask = player['mask']
                if mask is not None and np.sum(mask) > 0:
                    # Create a more vibrant mask overlay
                    alpha = 0.6  # Slightly more opaque for better visibility
                    vis_frame[mask] = (vis_frame[mask] * (1 - alpha) + np.array(color) * alpha).astype(np.uint8)
                    
                    # Draw mask contour for better definition
                    mask_uint8 = mask.astype(np.uint8) * 255
                    contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                    cv2.drawContours(vis_frame, contours, -1, color, 3)
                    
                    # Optional: Add a small track ID label at the center of the mask
                    if len(contours) > 0:
                        # Find the centroid of the largest contour
                        largest_contour = max(contours, key=cv2.contourArea)
                        M = cv2.moments(largest_contour)
                        if M["m00"] != 0:
                            center_x = int(M["m10"] / M["m00"])
                            center_y = int(M["m01"] / M["m00"])
                            
                            # Draw a small circle with track ID
                            cv2.circle(vis_frame, (center_x, center_y), 15, color, -1)
                            cv2.putText(vis_frame, str(track_id), (center_x - 8, center_y + 5), 
                                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            else:
                # Fallback: if no mask available, show a minimal indicator
                bbox = player['bbox']
                x1, y1, x2, y2 = [int(coord) for coord in bbox]
                center_x, center_y = (x1 + x2) // 2, (y1 + y2) // 2
                
                # Draw a small circle to indicate tracked player without mask
                cv2.circle(vis_frame, (center_x, center_y), 8, color, -1)
                cv2.putText(vis_frame, str(track_id), (center_x - 5, center_y + 3), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)
        
        # Draw performance info
        self._draw_performance_info(vis_frame)
        
        return vis_frame
    
    def visualize_tracking(self, frame: np.ndarray, tracked_players: List[Dict]) -> np.ndarray:
        """Visualize ByteTrack tracking results"""
        vis_frame = frame.copy()
        
        if not tracked_players:
            self._draw_performance_info(vis_frame)
            return vis_frame
        
        # Color palette for different track IDs
        color_palette = list(self.team_colors.values())[:-1]  # Exclude 'unknown'
        
        # Draw each tracked player
        for player in tracked_players:
            track_id = player['track_id']
            bbox = player['bbox']
            confidence = player.get('confidence', 0.0)
            
            x1, y1, x2, y2 = [int(coord) for coord in bbox]
            
            # Get consistent color for track ID
            color = color_palette[track_id % len(color_palette)]
            
            # Draw segmentation mask if available
            if player.get('has_mask', False) and 'mask' in player:
                mask = player['mask']
                if mask is not None and np.sum(mask) > 0:
                    # Direct pixel blending for colored masks
                    alpha = 0.4
                    vis_frame[mask] = (vis_frame[mask] * (1 - alpha) + np.array(color) * alpha).astype(np.uint8)
                    
                    # Draw mask contour
                    mask_uint8 = mask.astype(np.uint8) * 255
                    contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                    cv2.drawContours(vis_frame, contours, -1, color, 2)
            
            # Draw bounding box
            cv2.rectangle(vis_frame, (x1, y1), (x2, y2), color, 3)
            
            # Draw track information
            label = f"Player {track_id} ({confidence:.2f})"
            
            # Draw label with background
            label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]
            cv2.rectangle(vis_frame, (x1, y1 - label_size[1] - 10), 
                         (x1 + label_size[0] + 5, y1), color, -1)
            cv2.putText(vis_frame, label, (x1 + 2, y1 - 5), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            
            # Draw center point
            center_x, center_y = (x1 + x2) // 2, (y1 + y2) // 2
            cv2.circle(vis_frame, (center_x, center_y), 4, color, -1)
        
        # Draw performance info
        self._draw_performance_info(vis_frame)
        
        return vis_frame
    
    def _draw_performance_info(self, frame: np.ndarray):
        """Draw performance information on frame"""
        if not self.processing_times['total']:
            return
        
        # Calculate recent performance
        recent_times = self.processing_times['total'][-10:]
        avg_time = np.mean(recent_times)
        fps = 1.0 / avg_time if avg_time > 0 else 0
        
        # Calculate smoothing stats
        total_detections = len(getattr(self, '_last_raw_detections', []))
        smoothed_detections = len(getattr(self, '_last_smoothed_detections', []))
        
        # Performance text
        perf_text = f"FPS: {fps:.1f} | ByteTrack | Frame: {self.frame_count}"
        smooth_text = f"Detections: {total_detections}â†’{smoothed_detections} (smoothed)"
        
        # Draw background for both texts
        text_size1 = cv2.getTextSize(perf_text, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)[0]
        text_size2 = cv2.getTextSize(smooth_text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)[0]
        max_width = max(text_size1[0], text_size2[0])
        total_height = text_size1[1] + text_size2[1] + 25
        
        cv2.rectangle(frame, (10, 10), (max_width + 20, total_height), (0, 0, 0), -1)
        
        # Draw texts
        cv2.putText(frame, perf_text, (15, text_size1[1] + 15), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        cv2.putText(frame, smooth_text, (15, text_size1[1] + text_size2[1] + 20), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)
    
    def _update_statistics(self, tracked_players: List[Dict]):
        """Update session statistics"""
        self.session_stats['total_frames'] += 1
        self.session_stats['total_detections'] += len(tracked_players)
        
        for player in tracked_players:
            track_id = player['track_id']
            self.session_stats['unique_tracks'].add(track_id)
        
        current_players = len(tracked_players)
        self.session_stats['max_simultaneous_players'] = max(
            self.session_stats['max_simultaneous_players'], 
            current_players
        )
    
    def get_statistics(self) -> Dict:
        """Get comprehensive tracking statistics"""
        if not self.processing_times['total']:
            return {}
        
        # Calculate performance metrics
        avg_detection_time = np.mean(self.processing_times['detection'][-100:])
        avg_segmentation_time = np.mean(self.processing_times['segmentation'][-100:])
        avg_tracking_time = np.mean(self.processing_times['tracking'][-100:])
        avg_total_time = np.mean(self.processing_times['total'][-100:])
        avg_fps = 1.0 / avg_total_time if avg_total_time > 0 else 0
        
        # Get ByteTrack statistics
        tracker_stats = self.tracker.get_track_statistics()
        
        return {
            'method': 'ByteTrack',
            'optimization_level': self.optimization_level,
            'performance': {
                'avg_fps': avg_fps,
                'avg_detection_time_ms': avg_detection_time * 1000,
                'avg_segmentation_time_ms': avg_segmentation_time * 1000,
                'avg_tracking_time_ms': avg_tracking_time * 1000,
                'avg_total_time_ms': avg_total_time * 1000
            },
            'tracking': {
                'total_frames': self.session_stats['total_frames'],
                'total_detections': self.session_stats['total_detections'],
                'unique_tracks': len(self.session_stats['unique_tracks']),
                'max_simultaneous_players': self.session_stats['max_simultaneous_players'],
                'active_tracks': tracker_stats.get('active_tracks', 0)
            },
            'components': {
                'yolo_model': self.yolo_model,
                'sam2_enabled': self.sam2_available,
                'tracker_type': 'ByteTrack'
            }
        }
